# -*- coding: utf-8 -*-
"""channel_info.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U5YGCy4uv5bhLzorqe8tGTmE9fDNQQwf
"""

# import libraries 
from apiclient.discovery import build 
from urllib.parse import urlparse
from pathlib import Path
#done in google colab so using drive 
from google.colab import drive 
#mounting google drive to google colab 
drive.mount('/content/gdrive')
#importing OS to move between directorys in drive
import os
import time
import re
import pprint 
import json
import csv
import logging
import sys
import pandas as pd

# arguments to be passed to build function 
# Google Developer Key needed for YouTube Data API
DEVELOPER_KEY = "AIzaSyD3lX3yk9bWNNk1DcqKB6d-cMzLJsRhCPA" # pust your Google developer key here
#"AIzaSyAg2IZajtQ-GRF7AkIux2MMVAAk1eT_DKA"
YOUTUBE_API_SERVICE_NAME = "youtube"
YOUTUBE_API_VERSION = "v3"

class MemoryCache():
    _CACHE = {}

    def get(self, url):
        return MemoryCache._CACHE.get(url)

    def set(self, url, content):
        MemoryCache._CACHE[url] = content

# creating youtube resource object 
# for interacting with API 
youtube = build(YOUTUBE_API_SERVICE_NAME,  
                     YOUTUBE_API_VERSION, 
            developerKey = DEVELOPER_KEY,
               cache=MemoryCache())

def getVideosIds(path):
    ids = []
    videos = pd.read_csv(path)
    for i, row in videos.iterrows():
        ids.append(get_video_id(row['vid_url']))
    return ids

def getCurrentDirectory():
    return os.getcwd()

def getParentDirectory():
    return str(Path(os.getcwd()).parent)

def get_video_id(the_link):
    vid = re.findall('v(?:=|%3D)([^&%?]+)', urlparse(the_link).query)
    if vid:
        return vid[0]
    the_path = urlparse(the_link).path[1:]
    if ((not the_path) or 
        the_path.startswith('user') or 
        the_path.startswith('shared') or
        the_path.startswith('playlist') or
        the_path.startswith('channel') or 
        the_path.startswith('attribution_link') or 
        the_path.startswith('results') or 
        the_path.startswith('edit') or 
        the_path.startswith('categories') or 
        the_path.startswith('c/') or 
        the_path.startswith('view_play_list')): 
            return None
    if the_path.startswith('embed/'): return the_path[len('embed/'):len('embed/')+11]#typical length of the id
    if the_path.startswith('v/'): return the_path[len('v/'):len('v/')+11]
    
    return the_path

def jsonExists(vid_id, path):
    files_names = [ name for name in os.listdir(path) if name.startswith(vid_id) and not os.path.isdir(os.path.join(path, name)) ]
    return len(files_names) > 0

#results_file_path is the csv file for inputting that has youtube videos
results_file_path = '2944(2).csv'

def main():
    #used directly for connecting to google drive can take this out if working on different IDE.
    os.chdir('/content')
    counter = 0
    videos = []
    #retrieves all of the video IDS from the CSV file of YouTube videos
    ids = getVideosIds(results_file_path)
    

 
    count = 0
    checkCount = 0
 
    List = []
    vidList = []

    #going through each video ID
    for vid_id in ids:
        #calls the youtube.videos().list() method
        #to retrieve information on the videos
        list_videos_byid = youtube.videos().list(
          part="snippet",
          id=vid_id
      ).execute()
      
        #creates a list of that information
        results = list_videos_byid.get("items", [])
        
      
        #retrieves the channelID from 
        #the information of a video\ and appends it to the vidList list
        for result in results:
           details = result['snippet']['channelId']
           vidList.append(details)
   
    #removes all of the duplicate channels from the list
    #to make sure each channel is only present once
    uniqueChannels = list(dict.fromkeys(vidList))
    
    #write to csv file list of all the unique channels
    with open('list.csv', 'w') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(["Unique Channel Ids"])
            for channel in uniqueChannels:
                writer.writerow(["Channel Id: " + channel])

    
    #changes the directory to the output one
    os.chdir('/content/gdrive/Shared drives/channel/ch')

    #for each channel in the channel list
    for ch in uniqueChannels:
      try:
            #try to get channel information from the YouTube data API for a channel
            #such as general Info, subscribers, etc.
            list_channel = youtube.channels().list(
          part="snippet,contentDetails,statistics",
          id=ch
      ).execute()

      except:
            #if it doesn't find anything just skip
            list_channel = None
            
      #prints out all the channel information in json format to a json file
      with open(ch + '.json', 'w') as outfile:
               json.dump(obj=list_channel, indent=4, sort_keys=True, fp = outfile)
    
        
main()

print('Finished')
